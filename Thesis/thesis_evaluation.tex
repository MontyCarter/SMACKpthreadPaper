\chapter{Empirical Evaluation}\label{ch:evaluation}
In order to assess the accuracy and performance of the newly
implemented pthread extension to SMACK, I performed regression testing
and benchmarking to exercise the new model.  The design and results of
these tests are described in this section.

\section{Methodology}\label{sec:methodology}
Two types of testing were performed on the new implementation of
pthread support within SMACK: regression testing and benchmarking.

Regression tests were hand-written during model design and
implementation, and were targeted toward the intended behavior as I
interpreted it from the pthread specification.  Of course, all such
tests are passing, as the implementation was designed around these
regression tests.  These are worth mentioning, however, as they
demonstrate that the implementation models the basic behavior given by
the specification. 

In addition to regression testing, benchmark testing was also
performed to provide more realistic scenarios and input programs with
which to exercise the new pthread implementation.  The benchmark tests
were taken from the SVCOMP 2015 Concurrency category.  

The benchmarks selected were chosen for their ability to adequately
test the pthread implementation for accuracy. As SMACK is a bounded
software verifier, to thoroughly analyze programs, loops and recursion
are unrolled to a specified bound.  This provides a program with a
finite number of paths through the program, which allows for symbolic
execution.  A consequence of this transformation is that programs with
large or nested loops can see verification times grow 
exponentially. Benchmarks containing such loops were not
considered, as they do not focus on the accuracy of pthread support,
but rather on the ability of the verification tool to handle large
inputs.  Further, benchmarks were not considered if they required much
modification or additional support.  One such example of this is that
some benchmarks use an SVCOMP specific function name pattern.  Any
function starting with \lstinline|__VERIFIER_atomic_| should have its
instructions executed atomically from any other call to a function
also starting with \lstinline|__VERIFIER_atomic_|.  Supporting this
requires patching SMACK directly, and so benchmarks using this were
not considered.  In addition, there were other characteristics of
benchmarks which disqualified them from consideration.

The selected benchmarks were then analyzed individually to determine
the proper parameters that should be passed to SMACK during
verification.  As mentioned above, to thoroughly analyze a program, a
correct value must be set for the number of times to unroll loops.
Many benchmarks contain bugs that are only found during the
n\textsuperscript{th} iteration of a loop.  Finding such bugs requires a
proper selection of the number of times to unroll loops.  Similarly,
certain benchmarks contain bugs that are only discovered after a
certain number of context switches.  These two values were determined
for each benchmark in preparation for execution.

With the benchmarks selected, and proper bounding parameters
determined, the actual testing phase was carried out.  Testing was
performed on a Ubuntu installation with 12GB of memory and an Intel
i7-3740QM processor under minimal load.

As functionality and accuracy were the main goals of my
implementation, the results seen below come from single runs of each
benchmark.  Runtimes are provided simply to provide a very rough
comparison between SMACK and Lazy-CSeq, the winner of the 2015 SVCOMP
Concurrency category.   Future work will certainly include proper
benchmarking for performance. 

\section{Results and Analysis}
The results of the benchmark testing described in
Section~\ref{sec:methodology} are seen in
Table~\ref{table:benchmarkresults}.  Running times for Lazy-CSeq, the winner 
of the Concurrency category of the 2015 SVCOMP, are included for
comparison with SMACK's results.  Note that these are only useful for
rough comparisons -- the hardware setups were not configured
identically.  

\newcommand{\specialcell}[3][c]{%
  \begin{tabular}[#1]{@{}#2@{}}#3\end{tabular}}

\begin{table}[ht]
\centering
\begin{tabular}{|l|r|r|r|r|r|}
\hline 
\multicolumn{1}{|c|}{\bfseries{Benchmark}} & 
 \multicolumn{1}{c|}{\bfseries{LOC}} &
 \specialcell{c}{\bfseries{Thread}\\\bfseries{Count}} & 
 \specialcell{c}{\bfseries{Context}\\\bfseries{Switches}} &
 \specialcell{c}{\bfseries{SMACK}\\\bfseries{Runtime (s)}} &
 \specialcell{c}{\bfseries{Lazy-CSeq}\\\bfseries{Runtime (s)}} \\
\hline\hline
dekker\_true.c             & 62  & 3       & 3            & 2             & 4            \\
\hline
lamport\_true.c            & 83  & 3       & 3            & 3             & 5            \\
\hline
lazy01\_false.c            & 57  & 4       & 2            & 5             & 1            \\
\hline
peterson\_true.c           & 49  & 3       & 3            & 2             & 2            \\
\hline
qrcu\_false.c              & 155 & 4       & 3            & 102           & 1            \\
\hline
queue\_false.c             & 185 & 3       & 2            & \specialcell[c]{r}{180\\(Size=10)} &
                                                                \specialcell[c]{r}{18\\(Size=20)} \\
\hline
queue\_ok\_true.c          & 160 & 3       & 2            & \specialcell[c]{r}{295\\(Size=10)} &
                                                                \specialcell[c]{r}{51\\(Size=20)} \\
\hline
reorder\_2\_false.c        & 90  & 5       & 2            & 4             & 2            \\
\hline
reorder\_5\_false.c        & 88  & 6       & 2            & 11            & 3            \\
\hline
scull\_true.c              & 477 & 4       & 2            & N/A             & 5            \\
\hline
sigma\_false.c             & 55  & 6       & 2            & 85            & 9            \\
\hline
singleton\_false.c         & 64  & 7       & 2            & 75            & 3            \\
\hline
sssc12\_true.c             & 43  & 11      & 2            & 54            & 14           \\
\hline
stack\_false.c             & 127 & 3       & 2            & 18            & 1            \\
\hline
stack\_true.c              & 131 & 3       & 2            & 731           & 77           \\
\hline
stateful01\_false.c        & 62  & 3       & 2            & 5             & 1            \\
\hline
stateful01\_true.c         & 62  & 3       & 2            & 14            & 3            \\
\hline
sync01\_true.c             & 71  & 3       & 2            & 27            & 3            \\
\hline
szymanski\_true.c          & 62  & 3       & 2            & 2             & 3            \\
\hline
time\_var\_mutex\_true.c   & 62  & 3       & 2            & 22            & 3            \\
\hline
twostage\_3\_false.c       & 136 & 4       & 2            & 19            & 2            \\
\hline
\end{tabular}
\caption{SVCOMP Benchmark Results}\label{table:benchmarkresults}
\end{table}

The most remarkable aspect of the results is the rate of returning a
correct result. Only 1 of the 21 benchmarks,
\lstinline[identifierstyle=\color{black}]|scull_true.c|, did not
return the correct result.  The benchmarks successfully verified make
use of a wide array of the modeled pthread API, and span a wide range
of threads used.   The failing benchmark is currently in the process
of being analyzed to identify the cause of the incorrect result.

One disappointing aspect of the results is the performance relative to
the winner of the Concurrency category of the 2015 SVCOMP
competition.  Notice that with
\lstinline[identifierstyle=\color{black}]|queue_false.c| and
\lstinline[identifierstyle=\color{black}]|queue_ok_true.c|, the queue
size was reduced from an original 20 element queue to a 10 element
queue, and verification time was still an order of magnitude larger
than that of Lazy-CSeq.  Indeed, most of the benchmarks tested yield
substantially longer verification times than Lazy-CSeq.  It is
suspected that these significantly slower verification times are due
not only to the design of the pthread model, but also due largely to
inefficiencies in Corral. 

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
